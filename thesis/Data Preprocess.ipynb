{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Preprocess\n",
    "*Zhiang Chen, March 2017*\n",
    "\n",
    "This notebook is to get training dataset, validation dataset and test dataset. First, it reads the 24 pickle files. These 24 pickle files contain data from three different height of desk. For example, file [1-8] are from the height_1 of the desk; file [9-16] are from the height_2 of the desk; file [17-24] are from the height_3 of the desk. Two of the pickle files are randomly chosen from each 8 files to compose the validation dataset and test dataset. Three of them are randomly chosen as validation dataset, and the rest are the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import sample, shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Read pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir('pickle')\n",
    "dataset = dict()\n",
    "for file_name in files:\n",
    "    with open('pickle/'+file_name, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        dataset.setdefault(file_name, save['image'])\n",
    "        del save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Group dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', ['p1', 'p2', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10', 'p11', 'p12', 'p15', 'p16', 'p17', 'p19', 'p20', 'p21', 'p22', 'p24'])\n",
      "('valid', ['p4', 'p3', 'p23'])\n",
      "('test', ['p18', 'p14', 'p13'])\n"
     ]
    }
   ],
   "source": [
    "v_t = sample(xrange(1,9),2) + sample(xrange(9,17),2) + sample(xrange(16,25),2)\n",
    "shuffle(v_t)\n",
    "valid = v_t[:3]\n",
    "test = v_t[3:]\n",
    "train = list(set(range(1,25)) - set(v_t))\n",
    "\n",
    "def get_names(ls):\n",
    "    return ['p'+str(x) for x in ls]\n",
    "\n",
    "train = get_names(train)\n",
    "valid = get_names(valid)\n",
    "test = get_names(test)\n",
    "\n",
    "print('train',train)\n",
    "print('valid',valid)\n",
    "print('test',test)\n",
    "\n",
    "def add_dic(x,y):\n",
    "    return dict(x.items() + y.items())\n",
    "\n",
    "def get_data(name_list):\n",
    "    data = [dataset.get(name,False) for name in name_list]\n",
    "    return reduce(add_dic,data)\n",
    "\n",
    "# the dictionary is {name:numpy}; for example, one of the names is '30-8-1-gball-288.png'\n",
    "train_dataset = get_data(train)\n",
    "valid_dataset = get_data(valid)\n",
    "test_dataset = get_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "non_orientations = ['empty','cup','tball','pball','gball']\n",
    "\n",
    "def label_data(data):\n",
    "    objects = list()\n",
    "    orientations = list()\n",
    "    values = list()\n",
    "    for name, value in data.iteritems():\n",
    "        obj = name.split('.')[0].split('-')[-2] # object name\n",
    "        ori = name.split('.')[0].split('-')[-1] # orientation\n",
    "        objects.append(obj)\n",
    "        if obj in non_orientations:\n",
    "            orientations.append(0)\n",
    "        elif obj == 'gstick':\n",
    "            if name.split('.')[0].split('-')[2] in ['1','3']:\n",
    "                orientations.append(0)\n",
    "            else:\n",
    "                orientations.append(int(ori))\n",
    "        else:\n",
    "            orientations.append(int(ori))\n",
    "        values.append(value)\n",
    "    return objects, orientations, values\n",
    "\n",
    "train_objects, train_orientations, train_values = label_data(train_dataset)\n",
    "valid_objects, valid_orientations, valid_values = label_data(valid_dataset)\n",
    "test_objects, test_orientations, test_values = label_data(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Convert one-hot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "object2value = {'empty':0,'duck':1,'cup':2,'sponge':3,'tball':4,'pball':5,'gball':6,'gstick':7,'nerf':8,'calc':9,'stapler':10}\n",
    "value2object = dict((value,name) for name,value in object2value.items()) \n",
    "orientations = [18*x for x in range(20)]\n",
    "\n",
    "def convert_objects(objects):\n",
    "    obj_values = np.asarray([object2value[obj] for obj in objects])\n",
    "    return (np.arange(len(object2value)) == obj_values[:,None]).astype(np.float32)\n",
    "\n",
    "def convert_orientations(orientations):\n",
    "    ori_values = np.asarray(orientations)/18%10\n",
    "    return (np.arange(10) == ori_values[:,None]).astype(np.float32)\n",
    "\n",
    "train_objects_ = convert_objects(train_objects)\n",
    "valid_objects_ = convert_objects(valid_objects)\n",
    "test_objects_ = convert_objects(test_objects)\n",
    "\n",
    "train_orientations_ = convert_orientations(train_orientations)\n",
    "valid_orientations_ = convert_orientations(valid_orientations)\n",
    "test_orientations_ = convert_orientations(test_orientations)\n",
    "\n",
    "train_values_ = np.asarray(train_values).astype(np.float32)\n",
    "valid_values_ = np.asarray(valid_values).astype(np.float32)\n",
    "test_values_ = np.asarray(test_values).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data size: 638923.0kB\n"
     ]
    }
   ],
   "source": [
    "data_file = 'depth_data'\n",
    "with open(data_file,'wb') as f:\n",
    "    save={\n",
    "        'train_orientations':train_orientations_,\n",
    "        'valid_orientations':valid_orientations_,\n",
    "        'test_orientations':test_orientations_,\n",
    "        'train_objects':train_objects_,\n",
    "        'valid_objects':valid_objects_,\n",
    "        'test_objects':test_objects_,\n",
    "        'train_values':train_values_,\n",
    "        'valid_values':valid_values_,\n",
    "        'test_values':test_values_,\n",
    "        'object2value':object2value,\n",
    "        'value2object':value2object\n",
    "    }\n",
    "    pickle.dump(save,f,pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "statinfo = os.stat(data_file)\n",
    "file_size = float(statinfo.st_size)/1000\n",
    "print('Compressed data size: %0.1fkB' % file_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
